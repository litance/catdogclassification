import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torchvision.models import resnet18, ResNet18_Weights
from torch.utils.data import DataLoader, Dataset, random_split
from PIL import Image
import os
from tqdm import tqdm
# 1ï¸âƒ£ æŒ‡å®šæ•°æ®é›†è·¯å¾„
print("Torch Version:", torch.__version__)
print("Cuda Available:", torch.cuda.is_available())
print("Cuda:", torch.version.cuda)
DATASET_PATH = "" #æ•°æ®é›†è·¯å¾„
print("ğŸ” æ•°æ®é›†ç›®å½•:", DATASET_PATH)
# 2ï¸âƒ£ æ£€æŸ¥æ•°æ®é›†ç»“æ„
dataset_structure = os.listdir(DATASET_PATH)
print("ğŸ“‚ ç›®å½•å†…å®¹:", dataset_structure)
# åˆ¤æ–­æ•°æ®é›†æ˜¯å¦åŒ…å« 'cats' å’Œ 'dogs' æ–‡ä»¶å¤¹
if "cats" in dataset_structure and "dogs" in dataset_structure:
    root_dir = DATASET_PATH
else:
    raise FileNotFoundError("âŒ æœªæ‰¾åˆ° 'cats' å’Œ 'dogs' æ–‡ä»¶å¤¹ï¼Œè¯·æ£€æŸ¥æ•°æ®é›†ï¼")
print("âœ… ä½¿ç”¨æ•°æ®é›†ç›®å½•:", root_dir)
# 3ï¸âƒ£ æ•°æ®é¢„å¤„ç†ï¼ˆå¢å¼º + å½’ä¸€åŒ–ï¼‰
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # ç»Ÿä¸€å›¾ç‰‡å¤§å°
    transforms.RandomHorizontalFlip(),  # éšæœºæ°´å¹³ç¿»è½¬
    transforms.ToTensor(),  # è½¬æ¢ä¸º PyTorch Tensor
    transforms.Normalize([0.5], [0.5])  # å½’ä¸€åŒ–
])
# 4ï¸âƒ£ è‡ªå®šä¹‰æ•°æ®é›†ç±»
class CatDogDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.img_labels = []
        for label, cls in enumerate(["cats", "dogs"]):  # ç±»åˆ«æ˜ å°„ï¼šcats -> 0, dogs -> 1
            cls_dir = os.path.join(root_dir, cls)
            if not os.path.exists(cls_dir):
                raise FileNotFoundError(f"âŒ ç›®å½• {cls_dir} ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥æ•°æ®é›†ï¼")
            for img_name in os.listdir(cls_dir):
                img_path = os.path.join(cls_dir, img_name)
                if img_path.lower().endswith(('.png', '.jpg', '.jpeg')):  # è¿‡æ»¤éå›¾ç‰‡æ–‡ä»¶
                    self.img_labels.append((img_path, label))
    def __len__(self):
        return len(self.img_labels)
    def __getitem__(self, idx):
        img_path, label = self.img_labels[idx]
        image = Image.open(img_path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        return image, label
# 5ï¸âƒ£ åŠ è½½æ•°æ®é›†å¹¶åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†
full_dataset = CatDogDataset(root_dir=root_dir, transform=transform)
train_size = int(0.8 * len(full_dataset))  # 80% è®­ç»ƒé›†
val_size = len(full_dataset) - train_size  # 20% éªŒè¯é›†
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])
batch_size = 512  # å¯è°ƒæ•´ batch_size
num_workers = 0  # Windows è®¾ç½® num_workers=0 ä»¥é¿å… multiprocessing é—®é¢˜
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)
print(f"ğŸ“Š è®­ç»ƒæ ·æœ¬: {train_size}, éªŒè¯æ ·æœ¬: {val_size}")
# 6ï¸âƒ£ è®¾å¤‡é€‰æ‹©ï¼ˆè‡ªåŠ¨æ£€æµ‹ GPUï¼‰
device = torch.device("cuda:0")  # å¼ºåˆ¶ä½¿ç”¨ GPU 0
print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")
# 7ï¸âƒ£ å®šä¹‰ ResNet æ¨¡å‹ï¼ˆè¿ç§»å­¦ä¹ ï¼‰
model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)
model.fc = nn.Linear(512, 2)  # ä¿®æ”¹æœ€åä¸€å±‚ï¼Œè¾“å‡º 2 ä¸ªç±»åˆ«ï¼ˆçŒ« vs ç‹—ï¼‰
model = model.to(device)
# 8ï¸âƒ£ è®­ç»ƒå‚æ•°
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)  # æ¯ 5 ä¸ª epoch å­¦ä¹ ç‡å‡å°
# 9ï¸âƒ£ è®­ç»ƒæ¨¡å‹
def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=100):
    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        correct, total = 0, 0
        print(f"ğŸ“Œ Epoch [{epoch + 1}/{epochs}] å¼€å§‹è®­ç»ƒ...")
        # ğŸ”„ è®­ç»ƒè¿‡ç¨‹
        for images, labels in tqdm(train_loader, desc=f"ğŸš€ è®­ç»ƒä¸­ Epoch {epoch + 1}", leave=False):
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            _, predicted = outputs.max(1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)
        train_acc = 100 * correct / total
        scheduler.step()  # æ›´æ–°å­¦ä¹ ç‡
        print(f"ğŸ“Œ Epoch [{epoch + 1}/{epochs}], Loss: {running_loss:.4f}, Accuracy: {train_acc:.2f}%")
        # ğŸ” è¯„ä¼°æ¨¡å‹
        model.eval()
        val_correct, val_total, val_loss = 0, 0, 0.0
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                _, predicted = outputs.max(1)
                val_correct += (predicted == labels).sum().item()
                val_total += labels.size(0)
        val_acc = 100 * val_correct / val_total
        print(f"âœ… éªŒè¯é›† Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\n")
# **ğŸš€ è¿è¡Œè®­ç»ƒ**
if __name__ == '__main__':
    train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=10)
    # ğŸ”Ÿ ä¿å­˜æ¨¡å‹
    torch.save(model.state_dict(), "cat_dog_classifier.pth")
    print("âœ… æ¨¡å‹å·²ä¿å­˜ä¸º 'cat_dog_classifier.pth'")
